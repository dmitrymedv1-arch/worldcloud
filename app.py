import streamlit as st
from wordcloud import WordCloud
import io
import re
import pandas as pd
from collections import Counter

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤",
    page_icon="‚òÅÔ∏è",
    layout="wide"
)

# CSS —Å—Ç–∏–ª–∏
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: bold;
    }
    .stButton>button {
        background-color: #3B82F6;
        color: white;
        font-weight: bold;
        border-radius: 8px;
        border: none;
    }
    .stButton>button:hover {
        background-color: #2563EB;
    }
    .info-box {
        background-color: #F0F9FF;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #3B82F6;
        margin-bottom: 1rem;
    }
    .stat-box {
        background-color: #F8FAFC;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #E2E8F0;
    }
    .word-count {
        font-size: 0.9rem;
        color: #6B7280;
        margin-top: 0.5rem;
    }
    </style>
""", unsafe_allow_html=True)

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
def parse_input(text: str) -> dict[str, float]:
    """–ü–∞—Ä—Å–∏–Ω–≥ –≤–≤–æ–¥–∞ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –º–Ω–æ–≥–æ—Å–ª–æ–≤–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
    frequencies = {}
    lines = text.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –ø–æ–º–æ—â—å—é regex
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ (–≤–æ–∑–º–æ–∂–Ω–æ —Å % –∏–ª–∏ /) –≤ —Å—Ç—Ä–æ–∫–µ
        match = re.search(r'(.+?)\s+([-+]?\d*\.?\d+\s*%?)$', line.strip())
        
        if not match:
            # –ü—Ä–æ–±—É–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            if '\t' in line:
                parts = line.split('\t', 1)
            elif ':' in line:
                parts = line.split(':', 1)
            else:
                parts = re.split(r'\s+', line, 1)
            
            if len(parts) == 2:
                word = parts[0].strip()
                freq_str = parts[1].strip()
            else:
                continue
        else:
            word = match.group(1).strip()
            freq_str = match.group(2).strip()
        
        try:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
            if '%' in freq_str:
                freq_str = freq_str.replace('%', '').strip()
                freq = float(freq_str)
                # –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç > 1 (–Ω–∞–ø—Ä–∏–º–µ—Ä 50%), –¥–µ–ª–∏–º –Ω–∞ 100
                if freq > 1:
                    freq = freq / 100.0
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—Ä–æ–±–µ–π
            elif '/' in freq_str:
                num, denom = map(float, freq_str.split('/'))
                freq = num / denom
            else:
                freq = float(freq_str)
            
            if freq > 0:
                frequencies[word] = freq
                
        except ValueError:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –æ—à–∏–±–∫–∞–º–∏
            continue
    
    return frequencies

def normalize_frequencies(frequencies: dict[str, float]) -> dict[str, float]:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–æ—Ç –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-1"""
    if not frequencies:
        return frequencies
    
    max_freq = max(frequencies.values())
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –±–æ–ª—å—à–∏–µ —á–∏—Å–ª–∞
    if max_freq > 1.0:
        return {word: freq / max_freq for word, freq in frequencies.items()}
    
    return frequencies

def apply_filters(frequencies: dict[str, float], 
                  min_freq: float, 
                  scale: float, 
                  max_words: int) -> dict[str, float]:
    """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è"""
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —á–∞—Å—Ç–æ—Ç—É
    filtered = {k: v for k, v in frequencies.items() if v >= min_freq}
    
    if not filtered:
        return {}
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
    scaled = {k: v * scale for k, v in filtered.items()}
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
    if len(scaled) > max_words:
        sorted_items = sorted(scaled.items(), key=lambda x: x[1], reverse=True)
        scaled = dict(sorted_items[:max_words])
    
    return scaled

@st.cache_data(show_spinner=False)
def generate_wordcloud_image(frequencies: dict[str, float], 
                            settings: dict) -> io.BytesIO:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    if not frequencies:
        return None
    
    # –°–æ–∑–¥–∞–µ–º –æ–±–ª–∞–∫–æ —Å–ª–æ–≤
    wordcloud = WordCloud(
        width=settings['width'],
        height=settings['height'],
        background_color=settings['background_color'],
        colormap=settings['colormap'],
        max_words=settings['max_words'],
        min_font_size=settings['min_font_size'],
        max_font_size=settings['max_font_size'],
        random_state=42,
        collocations=False,
        prefer_horizontal=0.8,
        margin=2
    )
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±–ª–∞–∫–æ
    wordcloud.generate_from_frequencies(frequencies)
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ PIL Image –∏ –∑–∞—Ç–µ–º –≤ BytesIO
    img = wordcloud.to_image()
    buf = io.BytesIO()
    img.save(buf, format="PNG", optimize=True, quality=95)
    buf.seek(0)
    
    return buf

def display_statistics(frequencies: dict[str, float], 
                      total_words: int,
                      settings: dict):
    """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    col1, col2 = st.columns(2)
    
    with col1:
        with st.container(border=True):
            st.markdown("**üìà –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞**")
            st.write(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: **{total_words}**")
            st.write(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤: **{len(frequencies)}**")
            st.write(f"–ú–∏–Ω. —á–∞—Å—Ç–æ—Ç–∞: **{settings['min_frequency']}**")
            st.write(f"–ú–∞—Å—à—Ç–∞–±: **√ó{settings['scale']}**")
    
    with col2:
        with st.container(border=True):
            st.markdown("**üéØ –î–∏–∞–ø–∞–∑–æ–Ω —á–∞—Å—Ç–æ—Ç**")
            if frequencies:
                min_val = min(frequencies.values())
                max_val = max(frequencies.values())
                avg_val = sum(frequencies.values()) / len(frequencies)
                st.write(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: **{min_val:.4f}**")
                st.write(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: **{max_val:.4f}**")
                st.write(f"–°—Ä–µ–¥–Ω—è—è: **{avg_val:.4f}**")
    
    # –¢–æ–ø-20 —Å–ª–æ–≤
    st.markdown("**üèÜ –¢–æ–ø-20 —Å–ª–æ–≤ –ø–æ —á–∞—Å—Ç–æ—Ç–µ:**")
    sorted_words = sorted(frequencies.items(), key=lambda x: x[1], reverse=True)[:20]
    
    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    df = pd.DataFrame(sorted_words, columns=['–°–ª–æ–≤–æ', '–ß–∞—Å—Ç–æ—Ç–∞'])
    df.index = df.index + 1  # –ù–∞—á–∏–Ω–∞–µ–º —Å 1 –≤–º–µ—Å—Ç–æ 0
    
    # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤ 2 –∫–æ–ª–æ–Ω–∫–∏
    col1, col2 = st.columns(2)
    half = len(df) // 2 + len(df) % 2
    
    with col1:
        st.dataframe(df.iloc[:half][['–°–ª–æ–≤–æ', '–ß–∞—Å—Ç–æ—Ç–∞']], 
                    use_container_width=True,
                    hide_index=False)
    
    with col2:
        if len(df) > half:
            st.dataframe(df.iloc[half:][['–°–ª–æ–≤–æ', '–ß–∞—Å—Ç–æ—Ç–∞']], 
                        use_container_width=True,
                        hide_index=False)

# –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.markdown('<h1 class="main-header">‚òÅÔ∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤</h1>', unsafe_allow_html=True)

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    
    # –¶–≤–µ—Ç–æ–≤—ã–µ —Å—Ö–µ–º—ã
    color_schemes = {
        '–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è': 'viridis',
        '–ü–∞—Å—Ç–µ–ª—å–Ω–∞—è': 'Pastel1',
        '–¢–µ–º–Ω–∞—è': 'plasma',
        '–Ø—Ä–∫–∞—è': 'Set2',
        '–û–¥–Ω–æ—Å—Ç–æ—Ä–æ–Ω–Ω—è—è': 'coolwarm',
        '–¢–µ–ø–ª–∞—è': 'hot',
        '–û—Å–µ–Ω–Ω—è—è': 'autumn',
        '–†–∞–¥—É–≥–∞': 'rainbow'
    }
    
    selected_color = st.selectbox(
        "–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞",
        list(color_schemes.keys()),
        index=2
    )
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–º–µ—Ä–æ–≤
    col1, col2 = st.columns(2)
    with col1:
        min_font_size = st.slider("–ú–∏–Ω. —à—Ä–∏—Ñ—Ç", 5, 50, 10)
    with col2:
        max_font_size = st.slider("–ú–∞–∫—Å. —à—Ä–∏—Ñ—Ç", 50, 400, 200)
    
    # –î—Ä—É–≥–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    max_words = st.slider("–ú–∞–∫—Å. —Å–ª–æ–≤", 10, 200, 50, 5)
    scale = st.slider("–ú–∞—Å—à—Ç–∞–± —á–∞—Å—Ç–æ—Ç", 0.1, 10.0, 1.0, 0.1)
    min_frequency = st.number_input("–ú–∏–Ω. —á–∞—Å—Ç–æ—Ç–∞", 0.0, 1000.0, 0.0, 0.1)
    
    # –†–∞–∑–º–µ—Ä—ã –æ–±–ª–∞–∫–∞
    width = st.slider("–®–∏—Ä–∏–Ω–∞", 400, 1600, 1000, 50)
    height = st.slider("–í—ã—Å–æ—Ç–∞", 300, 1200, 600, 50)
    
    # –¶–≤–µ—Ç —Ñ–æ–Ω–∞
    background_color = st.color_picker("–¶–≤–µ—Ç —Ñ–æ–Ω–∞", "#FFFFFF")

# –û—Å–Ω–æ–≤–Ω–∞—è –æ–±–ª–∞—Å—Ç—å
with st.container():
    st.markdown("### üìù –í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ –æ–∫–Ω–æ
    with st.expander("üìã –§–æ—Ä–º–∞—Ç—ã –≤–≤–æ–¥–∞ (–Ω–∞–∂–º–∏—Ç–µ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞)"):
        st.markdown("""
        **–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:**
        - `Materials science 801` (—Ü–µ–ª—ã–µ —á–∏—Å–ª–∞)
        - `Chemistry 0.698` (–¥–µ—Å—è—Ç–∏—á–Ω—ã–µ –¥—Ä–æ–±–∏)
        - `Physics 50.40%` (–ø—Ä–æ—Ü–µ–Ω—Ç—ã)
        - `Engineering 395` (—Ç–∞–±—É–ª—è—Ü–∏—è –∏–ª–∏ –ø—Ä–æ–±–µ–ª)
        - `Composite material:473` (—á–µ—Ä–µ–∑ –¥–≤–æ–µ—Ç–æ—á–∏–µ)
        
        **–ü—Ä–∏–º–µ—Ä:**
        ```
        Materials science 801
        Chemistry 698
        Engineering 395
        Composite material 473
        Physics 504
        ```
        """)
    
    # –ü–æ–ª–µ –≤–≤–æ–¥–∞ —Å –ø—Ä–∏–º–µ—Ä–æ–º
    default_data = """Materials science\t801
Chemistry\t698
Engineering\t395
Composite material\t473
Physics\t504
Chemical engineering\t308
Metallurgy\t391
Nanotechnology\t285
Biomaterials\t267"""

    input_data = st.text_area(
        "–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ –∏ —á–∞—Å—Ç–æ—Ç—ã (–∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏):",
        value=default_data,
        height=200,
        label_visibility="collapsed"
    )
    
    # –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    parsed_data = parse_input(input_data)
    if parsed_data:
        st.caption(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ —Å–ª–æ–≤: {len(parsed_data)}")
    else:
        st.caption("‚ÑπÔ∏è –í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ")

# –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    generate_btn = st.button("üéØ –°–æ–∑–¥–∞—Ç—å –æ–±–ª–∞–∫–æ —Å–ª–æ–≤", use_container_width=True)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
if generate_btn:
    if not input_data.strip():
        st.error("‚ùå –í–≤–µ–¥–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤!")
        st.stop()
    
    with st.spinner("üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        # –ü–∞—Ä—Å–∏–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        frequencies = parse_input(input_data)
        
        if not frequencies:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç –≤–≤–æ–¥–∞.")
            st.stop()
        
        total_words = len(frequencies)
        frequencies = normalize_frequencies(frequencies)
        frequencies = apply_filters(frequencies, min_frequency, scale, max_words)
        
        if not frequencies:
            st.error(f"‚ùå –ù–µ—Ç —Å–ª–æ–≤ —Å —á–∞—Å—Ç–æ—Ç–æ–π –≤—ã—à–µ {min_frequency}!")
            st.stop()
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        settings = {
            'width': width,
            'height': height,
            'background_color': background_color,
            'colormap': color_schemes[selected_color],
            'max_words': max_words,
            'min_font_size': min_font_size,
            'max_font_size': max_font_size,
            'scale': scale,
            'min_frequency': min_frequency
        }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        with st.spinner("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤..."):
            img_buffer = generate_wordcloud_image(frequencies, settings)
        
        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        st.markdown("---")
        st.markdown("### ‚òÅÔ∏è –†–µ–∑—É–ª—å—Ç–∞—Ç")
        
        if img_buffer:
            # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            col1, col2, col3 = st.columns([1, 2, 1])
            with col2:
                st.image(img_buffer, use_container_width=True)
            
            # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            st.download_button(
                label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (PNG)",
                data=img_buffer,
                file_name="wordcloud.png",
                mime="image/png",
                use_container_width=True
            )
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            st.markdown("---")
            st.markdown("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
            display_statistics(frequencies, total_words, settings)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏—é –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            st.session_state['last_image'] = img_buffer.getvalue()
            st.session_state['last_frequencies'] = frequencies
            st.session_state['last_settings'] = settings
            st.session_state['total_words'] = total_words

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
elif 'last_image' in st.session_state:
    st.markdown("### ‚òÅÔ∏è –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±–ª–∞–∫–æ")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.image(st.session_state['last_image'], use_container_width=True)
    
    # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
    st.download_button(
        label="‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (PNG)",
        data=st.session_state['last_image'],
        file_name="wordcloud.png",
        mime="image/png",
        use_container_width=True
    )
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    st.markdown("---")
    st.markdown("### üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    display_statistics(
        st.session_state['last_frequencies'],
        st.session_state['total_words'],
        st.session_state['last_settings']
    )

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown(
    """
    <div style="text-align: center; color: #6B7280; padding: 1rem;">
        @devloped by daM ‚Ä¢ WordCloud Generator ‚Ä¢ 
    </div>
    """,
    unsafe_allow_html=True

)

